{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "import matplotlib.pyplot as plt\n",
    "from KNN import knn_predict_instance\n",
    "#from SVM import kernel_svm_train, kernel_svm_predict\n",
    "from plotutils import plot_data, plot_surface\n",
    "from kernelsvm import SVM\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cwd = os.getcwd() #if need the current directory \n",
    "df = pd.read_csv('digit-recognition/digit-recognition/train.csv')\n",
    "df2 = pd.read_csv('digit-recognition/digit-recognition/test.csv')\n",
    "#the shape of the dataframe is (38000, 785) meaning there are 38000 samples and 1 label with 784 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.iloc[0,:] to access a certain column or row by index\n",
    "#any other fun commands to put \n",
    "\n",
    "#try to interpret the data graphically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38000,)\n",
      "(38000, 784)\n"
     ]
    }
   ],
   "source": [
    "#turn the training dataframe into numpy array \n",
    "label_data_train = df.to_numpy()\n",
    "\n",
    "#column vector for the labels (38000,)\n",
    "label_train = label_data_train[:,0] \n",
    "\n",
    "#( 38000 x 784 matrix for the training data  )\n",
    "data_train = label_data_train[:, 1:] \n",
    "print(label_train.shape)\n",
    "print(data_train.shape)\n",
    "\n",
    "#turn testing dataframe into numpy array \n",
    "label_data_test = df2.to_numpy()\n",
    "label_test = label_data_test[:,0]\n",
    "data_test = label_data_test[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use sklearn library to try a KNN \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(data_train, label_train)\n",
    "knn_predictions = neigh.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performs feature extraction \n",
    "#code taken from https://medium.com/@basu369victor/handwritten-digits-recognition-d3d383431845\n",
    "#images aren't all same length so don't need to worry about scaling\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "list_hog = []\n",
    "list_hog1 = []\n",
    "for feature in data_train:\n",
    "    fd = hog(feature.reshape((28,28)), orientations=9, pixels_per_cell=(8,8),cells_per_block=(2,2),visualize=False ) #can probably optimize this\n",
    "    list_hog.append(fd) #4x4 seems to be optimal \n",
    "hog_features_train = np.array(list_hog, 'float64')\n",
    "\n",
    "#on testing data \n",
    "for feature in data_test:\n",
    "    fd = hog(feature.reshape((28,28)), orientations=9, pixels_per_cell=(8,8),cells_per_block=(2,2),visualize=False )\n",
    "    list_hog1.append(fd)\n",
    "hog_features_test = np.array(list_hog1, 'float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 144)\n",
      "(4000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hog visualization \n",
    "#code taken from https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html\n",
    "import matplotlib.pyplot as plt\n",
    "print(hog_features_test.shape)\n",
    "print(data_test.shape)\n",
    "image = data_test[5,:].reshape((28,28)) #can do this for multiple images \n",
    "\n",
    "fd, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
    "                    cells_per_block=(1, 1), visualize=True, multichannel=False)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 20), sharex=True, sharey=True)\n",
    "\n",
    "ax1.axis('off')\n",
    "ax1.imshow(image, cmap=plt.cm.gray)\n",
    "ax1.set_title('Input image')\n",
    "\n",
    "# Rescale histogram for better display\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "ax2.axis('off')\n",
    "ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax2.set_title('Histogram of Oriented Gradients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "#Use sklearn library to try SVM model \n",
    "#linear appears to work the best with HOG \n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "clf = OneVsOneClassifier(svm.LinearSVC(C=0.030)) #performs slightyly better on SVM both linear and RBF\n",
    "#clf = OneVsOneClassifier(svm.SVC(gamma = 0.01, C=.030))\n",
    "clf.fit(hog_features_train, label_train)\n",
    "svm_predictions = clf.predict(hog_features_test)\n",
    "print(svm_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "clf = OneVsOneClassifier(svm.SVC()) #takes a very very long time to run\n",
    "clf.fit(data_train, label_train)\n",
    "svm_predictions = clf.predict(data_test)\n",
    "print(svm_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38000,)\n",
      "(4000,)\n",
      "SVM Accuracy: 0.9775\n"
     ]
    }
   ],
   "source": [
    "#compute accuracy using sklearn \n",
    "from sklearn import metrics\n",
    "print(label_train.shape)\n",
    "print(label_test.shape)\n",
    "#print(\"KNN Accuracy:\",metrics.accuracy_score(label_test, knn_predictions))\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(label_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unewighted KNN with euclidean distance for an instance \n",
    "#calculate using euclidean distance \n",
    "#would be data_test.shape[0]\n",
    "knn_predicts = []\n",
    "for i in range(data_test.shape[0]):\n",
    "    knn_predicts.append(knn_predict_instance(data_train, label_train, data_test[i,:], 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "0.973\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "print(len(knn_predicts))\n",
    "for i in range(data_test.shape[0]):\n",
    "    if label_test[i]==knn_predicts[i]:\n",
    "        correct = correct+1\n",
    "print(correct/4000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use sklearn library to try a KNN with HOG \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(hog_features_train, label_train)\n",
    "knn_predictions = neigh.predict(hog_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for one vs all approach \n",
    "label_train1 = np.where(label_train==1, label_train, -1)\n",
    "label_train2 = np.where(label_train==2, 1, -1)\n",
    "label_train3 = np.where(label_train==3, 1, -1)\n",
    "label_train4 = np.where(label_train==4, 1, -1)\n",
    "label_train5 = np.where(label_train==5, 1, -1)\n",
    "label_train6 = np.where(label_train==6, 1, -1)\n",
    "label_train7 = np.where(label_train==7, 1, -1)\n",
    "label_train8 = np.where(label_train==8, 1, -1)\n",
    "label_train9 = np.where(label_train==9, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0022e+04 -2.0404e+07  2e+07  1e-03  2e-07\n",
      " 1: -2.0061e+04 -2.4398e+05  2e+05  2e-05  2e-09\n",
      " 2: -2.3372e+04 -4.2376e+04  2e+04  1e-06  3e-08\n",
      " 3: -3.9838e+04 -4.1389e+04  2e+03  6e-08  1e-07\n",
      " 4: -4.0002e+04 -4.0018e+04  2e+01  7e-10  3e-09\n",
      " 5: -4.0004e+04 -4.0004e+04  2e-01  1e-09  6e-11\n",
      " 6: -4.0004e+04 -4.0004e+04  2e-03  1e-09  4e-11\n",
      "Optimal solution found.\n",
      "40 support vectors out of 380 points\n",
      "label_test: [1 0 1 ... 6 6 4]\n",
      "400 out of 4000 predictions correct\n"
     ]
    }
   ],
   "source": [
    "# Run polynomial SVM\n",
    "train_data = np.split(data_train, 100)\n",
    "train_labels = np.split(label_train, 100)\n",
    "polynomialSVM = SVM(C=1000.1)\n",
    "polynomialSVM.fit(train_data[0], train_labels[0])\n",
    "\n",
    "print(\"label_test: {0}\".format(label_test))\n",
    "predictions = polynomialSVM.predict(data_test)\n",
    "print(\"predictions: {0}\".format(predictions))\n",
    "correct = np.sum(predictions == label_test)\n",
    "print(\"%d out of %d predictions correct\" % (correct, len(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 38000)\n"
     ]
    }
   ],
   "source": [
    "#Attempt at one vs one approach \n",
    "#maybe use np arg where? \n",
    "data_train=hog_features_train.T #transpoe so columns are the sample data\n",
    "print(data_train.shape)\n",
    "locations1 = np.argwhere(label_train==1)\n",
    "locations2 = np.argwhere(label_train==2)\n",
    "locations1 = np.ndarray.flatten(locations1)\n",
    "locations2 = np.ndarray.flatten(locations2)\n",
    "data_train[:,np.append(locations1,locations2)]\n",
    "best_params = {}\n",
    "best_params['kernel'] = 'linear'\n",
    "best_params['C'] = 1\n",
    "label_train[np.logical_or(label_train==1,label_train==2)]\n",
    "#whaat happens when try to run a multi-class on the single class SVM model? \n",
    "#may need to change the labels \n",
    "part = data_train[:,np.append(locations1,locations2)]\n",
    "compare = label_train[np.logical_or(label_train==1,label_train==2)] #somehow still seems to work interesting \n",
    "compare = np.where(compare==1, compare, -1) #as model only takes 1, -1\n",
    "lin_svm_model1 = kernel_svm_train(part, compare, best_params) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
